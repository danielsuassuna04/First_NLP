{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ht60IDNHe6fX",
        "outputId": "95f32817-466f-4887-ffd0-c66d0d6b0ac3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-02 19:29:24.440851: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-02 19:29:24.440910: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-02 19:29:24.441944: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-02 19:29:24.448447: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-10-02 19:29:25.160715: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow\n",
        "np.random.seed(0)\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
        "from tensorflow.keras.layers import Embedding\n",
        "np.random.seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uL41Apdrnwgh"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "def read_csv(filename = 'data/emojify_data.csv'):\n",
        "    phrase = []\n",
        "    emoji = []\n",
        "\n",
        "    with open (filename) as csvDataFile:\n",
        "        csvReader = csv.reader(csvDataFile)\n",
        "\n",
        "        for row in csvReader:\n",
        "            phrase.append(row[0])\n",
        "            emoji.append(row[1])\n",
        "\n",
        "    X = np.asarray(phrase)\n",
        "    Y = np.asarray(emoji, dtype=int)\n",
        "\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_T5OTpigpFC"
      },
      "outputs": [],
      "source": [
        "X_train, Y_train = read_csv('train_emoji.csv')\n",
        "X_test, Y_test = read_csv('tesss.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "UpNJiX4-jcoO",
        "outputId": "c562f3d5-857c-4c03-fd61-131775bbe979"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['never talk to me again', 'I am proud of your achievements',\n",
              "       'It is the worst day in my life', 'Miss you so much',\n",
              "       'food is life', 'I love you mum', 'Stop saying bullshit',\n",
              "       'congratulations on your acceptance',\n",
              "       'The assignment is too long ', 'I want to go play',\n",
              "       'she did not answer my text ', 'Your stupidity has no limit',\n",
              "       'how many points did he score', 'my algorithm performs poorly',\n",
              "       'I got approved', 'Stop shouting at me',\n",
              "       'Sounds like a fun plan ha ha', 'no one likes him',\n",
              "       'the game just finished', 'I will celebrate soon',\n",
              "       'So sad you are not coming', 'She is my dearest love', 'Good job',\n",
              "       'It was funny lol', 'candy is life ', 'The chicago cubs won again',\n",
              "       'I am hungry', 'I am so excited to see you after so long',\n",
              "       'you did well on you exam', 'lets brunch some day',\n",
              "       'he is so cute', 'How dare you ask that',\n",
              "       'do you want to join me for dinner ', 'I said yes',\n",
              "       'she is attractive', 'you suck', 'she smiles a lot',\n",
              "       'he is laughing', 'she takes forever to get ready ',\n",
              "       'French macaroon is so tasty', 'we made it', 'I am excited',\n",
              "       'I adore my dogs', 'Congratulations', 'this girl was mean',\n",
              "       'you two are cute',\n",
              "       'my code is working but the grader gave me zero',\n",
              "       'this joke is killing me haha', 'do you like pizza ',\n",
              "       'you got a down grade', 'I missed you',\n",
              "       'I think I will end up alone', 'I got humiliated by my sister',\n",
              "       'you are awful', 'I cooked meat', 'This is so funny',\n",
              "       'lets exercise', 'he is the best player',\n",
              "       'I am going to the stadium',\n",
              "       'You are incredibly intelligent and talented',\n",
              "       'Stop shouting at me', 'Who is your favorite player',\n",
              "       'I like you a lot', 'i miss him', 'my dog just had a few puppies',\n",
              "       'I hate him', 'I want chinese food', 'cookies are good',\n",
              "       'her smile is so charming',\n",
              "       'Bravo for the announcement it got a lot of traction',\n",
              "       'she plays baseball', 'he did an amazing job',\n",
              "       'The baby is adorable', 'I was waiting for her for two hours ',\n",
              "       'funny', 'I like it when people smile', 'I love dogs',\n",
              "       'they are so kind and friendly',\n",
              "       'So bad that you cannot come with us', 'he likes baseball',\n",
              "       'I am so impressed by your dedication to this project',\n",
              "       'I am at the baseball game', 'Bravo', 'What a fun moment',\n",
              "       'I want to have sushi for dinner', 'I am very disappointed',\n",
              "       'he can not do anything', 'lol', 'Lets have food together',\n",
              "       'she is so cute', 'miss you my dear', 'I am looking for a date',\n",
              "       'I am frustrated', 'I lost my wallet', 'you failed the midterm',\n",
              "       'ha ha ha it was so funny', 'Do you want to give me a hug',\n",
              "       'who is playing in the final', 'she is happy',\n",
              "       'You are not qualified for this position', 'I love my dad',\n",
              "       'this guy was such a joke', 'Good joke',\n",
              "       'This specialization is great', 'you could not solve it',\n",
              "       'I am so happy for you', 'Congrats on the new job',\n",
              "       'I am proud of you forever', 'I want to eat',\n",
              "       'That catcher sucks ', 'The first base man got the ball',\n",
              "       'this is bad', 'you did not do your homework',\n",
              "       'I will have a cheese cake', 'do you have a ball',\n",
              "       'the lectures are great though ',\n",
              "       'Are you down for baseball this afternoon',\n",
              "       'what are the rules of the game', 'I am always working',\n",
              "       'where is the stadium',\n",
              "       'She is the cutest person I have ever seen',\n",
              "       'vegetables are healthy', 'he is handsome',\n",
              "       'too bad that you were not here', 'you are a loser',\n",
              "       'I love indian food', 'Who is down for a restaurant',\n",
              "       'he had to make a home run', 'I am ordering food',\n",
              "       'What is wrong with you', 'I love you', 'great job'], dtype='<U52')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfnQ9FVAjgTs"
      },
      "outputs": [],
      "source": [
        "maxLen = len(max(X_train, key=lambda x: len(x.split())).split())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYe4Zrtgjl4M"
      },
      "outputs": [],
      "source": [
        "label_to_emoji = {0: \"❤️\", 1: \"⚾:\", 2: \"😊\", 3: \"😞\", 4: \"🍴\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e_qoO0Ijiax",
        "outputId": "b87a48b0-7eae-4bb8-a5d9-3104e0f34440"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "never talk to me again 😞\n",
            "I am proud of your achievements 😊\n",
            "It is the worst day in my life 😞\n",
            "Miss you so much ❤️\n",
            "food is life 🍴\n",
            "I love you mum ❤️\n",
            "Stop saying bullshit 😞\n",
            "congratulations on your acceptance 😊\n",
            "The assignment is too long  😞\n",
            "I want to go play ⚾:\n"
          ]
        }
      ],
      "source": [
        "for idx in range(10):\n",
        "    print(X_train[idx], label_to_emoji[Y_train[idx]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDf2ocdTe-zU"
      },
      "outputs": [],
      "source": [
        "\n",
        "def sentences_to_indices(X, word_to_index, max_len):\n",
        "\n",
        "    m = X.shape[0]\n",
        "    X_indices = np.zeros((m, max_len))\n",
        "\n",
        "    for i in range(m):\n",
        "        sentence_words = sentence_words = X[i].lower().split()\n",
        "        j = 0\n",
        "        for w in sentence_words:\n",
        "            if w in word_to_index:\n",
        "                X_indices[i, j] = word_to_index[w]\n",
        "                j =  j + 1\n",
        "    return X_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EM3D4alrfU7B"
      },
      "outputs": [],
      "source": [
        "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
        "\n",
        "    vocab_size = len(word_to_index) + 1\n",
        "    any_word = next(iter(word_to_vec_map.keys()))\n",
        "    emb_dim = word_to_vec_map[any_word].shape[0]\n",
        "    emb_matrix = np.zeros((vocab_size, emb_dim))\n",
        "    for word, idx in word_to_index.items():\n",
        "        emb_matrix[idx, :] = word_to_vec_map[word]\n",
        "    embedding_layer = Embedding(vocab_size, emb_dim, trainable=False)\n",
        "    embedding_layer.build((None,))\n",
        "    embedding_layer.set_weights([emb_matrix])\n",
        "\n",
        "    return embedding_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7kJZFgpfm6c"
      },
      "outputs": [],
      "source": [
        "def Emojify_V2(input_shape, word_to_vec_map, word_to_index):\n",
        "\n",
        "    sentence_indices = sentence_indices = Input(input_shape, dtype='int32')\n",
        "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
        "    embeddings = embedding_layer(sentence_indices)\n",
        "    X = LSTM(128, return_sequences=True)(embeddings)\n",
        "    X = Dropout(0.5)(X)\n",
        "    X = LSTM(128, return_sequences=False)(X)\n",
        "    X = Dropout(0.5)(X)\n",
        "    X = Dense(5)(X)\n",
        "    X = Activation('softmax')(X)\n",
        "    model = Model(sentence_indices, X)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTjkRIUflSg6"
      },
      "outputs": [],
      "source": [
        "\n",
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)]\n",
        "    return Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3sX-3cZmAx8"
      },
      "outputs": [],
      "source": [
        "def read_glove_vecs(glove_file):\n",
        "    with open(glove_file, 'r') as f:\n",
        "        words = set()\n",
        "        word_to_vec_map = {}\n",
        "        for line in f:\n",
        "                line = line.strip().split()\n",
        "                curr_word = line[0]\n",
        "                words.add(curr_word)\n",
        "                word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
        "\n",
        "        i = 1\n",
        "        words_to_index = {}\n",
        "        index_to_words = {}\n",
        "        for w in sorted(words):\n",
        "                words_to_index[w] = i\n",
        "                index_to_words[i] = w\n",
        "                i = i + 1\n",
        "        return words_to_index, index_to_words, word_to_vec_map\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "su8vrGsg5aJS",
        "outputId": "7b703591-8194-4027-a332-596651ec9489"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.3)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.11.2)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (6.4.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGEAsUumrHvH",
        "outputId": "7de3e416-6c18-4719-93ad-ee10fe1518e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vetor para 'word': [ 3.59375000e-01  4.15039062e-02  9.03320312e-02  5.46875000e-02\n",
            " -1.47460938e-01  4.76074219e-02 -8.49609375e-02 -2.04101562e-01\n",
            "  3.10546875e-01 -1.05590820e-02 -6.15234375e-02 -1.55273438e-01\n",
            " -1.52343750e-01  8.54492188e-02 -2.70996094e-02  3.84765625e-01\n",
            "  4.78515625e-02  2.58789062e-02  4.49218750e-02 -2.79296875e-01\n",
            "  9.09423828e-03  4.08203125e-01  2.40234375e-01 -3.06640625e-01\n",
            " -1.80664062e-01  4.73632812e-02 -2.63671875e-01  9.08203125e-02\n",
            "  1.37695312e-01 -7.20977783e-04  2.67333984e-02  1.92382812e-01\n",
            " -2.29492188e-02  9.70458984e-03 -7.37304688e-02  4.29687500e-01\n",
            " -7.93457031e-03  1.06445312e-01  2.80761719e-02 -2.29492188e-01\n",
            " -1.91650391e-02 -2.36816406e-02  3.51562500e-02  1.71875000e-01\n",
            " -1.12304688e-01  6.25000000e-02 -1.69921875e-01  1.29882812e-01\n",
            " -1.54296875e-01  1.58203125e-01 -7.76367188e-02  1.78710938e-01\n",
            " -1.72851562e-01  9.96093750e-02  3.94531250e-01  6.44531250e-02\n",
            " -6.83593750e-02 -3.18359375e-01  5.95703125e-02 -1.02539062e-02\n",
            "  9.37500000e-02  8.25195312e-02 -2.52685547e-02  1.09863281e-01\n",
            " -6.73828125e-02 -1.70898438e-01  6.78710938e-02  1.04492188e-01\n",
            " -2.11914062e-01  1.30859375e-01 -1.24573708e-05  1.85546875e-02\n",
            " -1.61132812e-01 -8.00781250e-02  9.42382812e-02 -8.78906250e-02\n",
            "  1.82617188e-01 -2.48718262e-03  8.74023438e-02  1.75781250e-01\n",
            " -2.17285156e-02 -1.96289062e-01  9.52148438e-02 -5.15136719e-02\n",
            "  1.01928711e-02  6.22558594e-02 -2.13867188e-01  2.25585938e-01\n",
            "  2.46093750e-01 -6.12792969e-02  1.74560547e-02 -1.46484375e-01\n",
            "  3.93676758e-03 -1.62109375e-01 -1.10839844e-01  6.88476562e-02\n",
            " -1.83593750e-01  1.13281250e-01  9.08203125e-02 -1.64062500e-01\n",
            " -3.71093750e-01 -5.39550781e-02 -8.66699219e-03 -1.18164062e-01\n",
            " -5.93261719e-02  8.74023438e-02 -1.98242188e-01 -1.36718750e-01\n",
            "  6.39648438e-02 -1.88476562e-01 -2.96875000e-01  6.39648438e-02\n",
            "  2.16796875e-01 -7.71484375e-02  1.13769531e-01  1.96533203e-02\n",
            "  2.31445312e-01  6.59179688e-02  1.02539062e-01 -6.39648438e-02\n",
            " -1.48437500e-01 -5.59082031e-02 -2.43164062e-01  2.71484375e-01\n",
            "  1.83593750e-01  3.06396484e-02 -2.01416016e-02 -1.53320312e-01\n",
            "  7.08007812e-02 -2.35595703e-02 -9.66796875e-02 -2.83203125e-01\n",
            " -2.57568359e-02 -7.42187500e-02 -4.27246094e-02  6.98242188e-02\n",
            " -1.74804688e-01  2.27539062e-01  2.92968750e-01 -1.86767578e-02\n",
            "  2.94921875e-01 -1.12304688e-01  4.85839844e-02 -2.15820312e-01\n",
            "  1.03149414e-02 -1.14257812e-01 -6.39648438e-02  7.27539062e-02\n",
            " -1.47460938e-01 -2.16796875e-01  1.32812500e-01  1.83593750e-01\n",
            " -1.48437500e-01 -1.31835938e-01 -3.73535156e-02  1.19628906e-01\n",
            " -2.01171875e-01  1.00097656e-01 -8.93554688e-02  1.23596191e-03\n",
            "  7.17773438e-02  1.42578125e-01 -3.03955078e-02 -1.89453125e-01\n",
            " -8.88671875e-02  3.83300781e-02 -1.74804688e-01 -3.66210938e-03\n",
            " -2.08007812e-01  8.97216797e-03  2.35351562e-01  1.06933594e-01\n",
            " -2.65625000e-01 -2.16796875e-01  7.08007812e-02  9.08203125e-02\n",
            "  3.00781250e-01 -1.07421875e-01  1.01562500e-01 -6.25000000e-02\n",
            "  1.33789062e-01 -1.62353516e-02  2.50000000e-01 -1.72851562e-01\n",
            "  3.32031250e-01  1.12304688e-01 -1.47705078e-02 -1.04980469e-01\n",
            " -8.05664062e-02  3.30078125e-01  9.32617188e-02 -1.47460938e-01\n",
            " -2.05078125e-01 -7.56835938e-02 -1.04492188e-01  6.25000000e-02\n",
            " -2.02148438e-01 -1.09375000e-01 -8.05664062e-02  5.49316406e-02\n",
            " -8.88671875e-02  5.24902344e-02 -2.23632812e-01  5.17578125e-02\n",
            " -1.83593750e-01 -6.73828125e-02 -9.13085938e-02  1.29882812e-01\n",
            " -2.31933594e-02 -1.04003906e-01  1.79687500e-01  8.34960938e-02\n",
            " -8.78906250e-02 -2.17773438e-01 -6.34765625e-02  1.33789062e-01\n",
            "  1.62109375e-01  2.87109375e-01 -1.14257812e-01  6.05468750e-02\n",
            "  1.49414062e-01 -3.08227539e-03  1.96289062e-01 -8.98437500e-02\n",
            "  1.45507812e-01  1.02539062e-02  1.22070312e-02  3.20312500e-01\n",
            "  1.24511719e-01  1.20849609e-02 -1.78710938e-01  3.71093750e-02\n",
            "  6.98242188e-02  1.62109375e-01  9.86328125e-02 -2.61718750e-01\n",
            "  1.89453125e-01 -2.83203125e-02  4.06250000e-01  3.56445312e-02\n",
            "  3.10058594e-02  2.27050781e-02  1.30859375e-01 -1.05957031e-01\n",
            "  8.69140625e-02 -9.76562500e-02  1.89453125e-01  3.17382812e-02\n",
            "  1.10351562e-01  2.11914062e-01 -1.66992188e-01  1.45263672e-02\n",
            "  1.15234375e-01  1.59179688e-01  9.91210938e-02 -2.40234375e-01\n",
            " -2.34375000e-01  1.74804688e-01  1.20605469e-01 -3.67187500e-01\n",
            " -7.81250000e-02  1.10839844e-01 -3.35937500e-01 -9.81445312e-02\n",
            " -7.47070312e-02 -1.89453125e-01  7.81250000e-02 -2.53906250e-01\n",
            " -6.03027344e-02 -2.46093750e-01 -9.37500000e-02  8.64257812e-02\n",
            "  1.15722656e-01 -1.24511719e-01  1.61132812e-01 -6.03027344e-02\n",
            " -2.47070312e-01 -9.52148438e-02 -4.05273438e-02  2.51953125e-01\n",
            " -1.95312500e-01 -1.31835938e-01  6.88476562e-02  2.67333984e-02\n",
            "  1.03027344e-01  1.05957031e-01 -3.01513672e-02  3.04687500e-01\n",
            " -8.74023438e-02  1.19140625e-01 -1.74560547e-02  8.78906250e-03\n",
            " -1.38671875e-01 -2.85156250e-01  2.29492188e-01 -3.55468750e-01\n",
            "  9.52148438e-03 -4.07714844e-02 -8.88671875e-02 -1.39160156e-02]\n",
            "Similaridade entre 'king' e 'queen': 0.6510957\n",
            "Palavras mais similares a 'king': [('kings', 0.7138045430183411), ('queen', 0.6510956883430481), ('monarch', 0.6413194537162781), ('crown_prince', 0.6204220056533813), ('prince', 0.6159993410110474)]\n",
            "'king' está no vocabulário.\n"
          ]
        }
      ],
      "source": [
        "from gensim.downloader import load\n",
        "\n",
        "# Carregar o modelo Word2Vec do Gensim\n",
        "model = load('word2vec-google-news-300')\n",
        "\n",
        "# Acessar o vetor de uma palavra\n",
        "word_vector = model['word']  # Exemplo: obter o vetor para a palavra \"word\"\n",
        "print(\"Vetor para 'word':\", word_vector)\n",
        "\n",
        "# Acessar a similaridade entre duas palavras\n",
        "similarity = model.similarity('king', 'queen')\n",
        "print(\"Similaridade entre 'king' e 'queen':\", similarity)\n",
        "\n",
        "# Encontrar palavras mais similares a uma palavra dada\n",
        "similar_words = model.most_similar('king', topn=5)\n",
        "print(\"Palavras mais similares a 'king':\", similar_words)\n",
        "\n",
        "# Verifique se a palavra está no vocabulário\n",
        "if 'king' in model:\n",
        "    print(\"'king' está no vocabulário.\")\n",
        "else:\n",
        "    print(\"'king' não está no vocabulário.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vA9gzfusrQtK"
      },
      "outputs": [],
      "source": [
        "word_to_index = {word: index for index, word in enumerate(model.index_to_key)}\n",
        "index_to_word = {index: word for index, word in enumerate(model.index_to_key)}\n",
        "word_to_vec_map = {word: model[word] for word in model.index_to_key}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "HpyOrphtf-JY",
        "outputId": "691bf0c1-be54-4b34-ea0b-8a3742f55559"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-02 19:31:05.492857: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-10-02 19:31:05.539143: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-10-02 19:31:05.539351: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-10-02 19:31:05.540534: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-10-02 19:31:05.540668: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-10-02 19:31:05.540757: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-10-02 19:31:06.629748: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-10-02 19:31:06.629948: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-10-02 19:31:06.630056: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-10-02 19:31:06.630133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14223 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:00:05.0, compute capability: 8.6\n",
            "2024-10-02 19:31:15.850987: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 3600001200 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 10)]              0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 10, 300)           900000300 \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 10, 128)           219648    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 10, 128)           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 645       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 900352177 (3.35 GB)\n",
            "Trainable params: 351877 (1.34 MB)\n",
            "Non-trainable params: 900000300 (3.35 GB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Emojify_V2((maxLen,), word_to_vec_map, word_to_index)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywlbhnPHgD1W"
      },
      "outputs": [],
      "source": [
        "X_train_indices = sentences_to_indices(X_train, word_to_index, maxLen)\n",
        "Y_train_oh = convert_to_one_hot(Y_train, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPuGeVN-njO9"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDumUdTYnUHl",
        "outputId": "4fd9ca87-59f4-4263-97e0-e860b9575885"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-02 19:31:29.527631: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
            "2024-10-02 19:31:30.494759: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f08e43364b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2024-10-02 19:31:30.494801: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A4000, Compute Capability 8.6\n",
            "2024-10-02 19:31:30.523476: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1727897490.681411     223 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 6s 6ms/step - loss: 1.5854 - accuracy: 0.3030\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.5002 - accuracy: 0.3485\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.4457 - accuracy: 0.3182\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.3281 - accuracy: 0.3788\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1.2212 - accuracy: 0.4773\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.9552 - accuracy: 0.7121\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.7349 - accuracy: 0.7652\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5246 - accuracy: 0.8636\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.4420 - accuracy: 0.8561\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.3615 - accuracy: 0.8712\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4002 - accuracy: 0.8788\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2648 - accuracy: 0.9242\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.2689 - accuracy: 0.9242\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1465 - accuracy: 0.9621\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1119 - accuracy: 0.9773\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.1121 - accuracy: 0.9773\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0692 - accuracy: 0.9773\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0429 - accuracy: 0.9924\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.9924\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0288 - accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0187 - accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0160 - accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0088 - accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f0bcf0a1250>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train_indices, Y_train_oh, epochs = 50, batch_size = 32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJBcUHC7ng97",
        "outputId": "66b3203b-7db5-432f-c394-1ef119f28518"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[5530.  172.   78.  589.    0.    0.    0.    0.    0.    0.]]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "lets play some ball ⚾:\n"
          ]
        }
      ],
      "source": [
        "x_test = np.array(['lets play some ball'])\n",
        "X_test_indices = sentences_to_indices(x_test, word_to_index, maxLen)\n",
        "print(X_test_indices)\n",
        "print(x_test[0] +' '+  label_to_emoji[np.argmax(model.predict(X_test_indices))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihbPvHXno1jb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}